# combine_data.py
import pandas as pd
import os

print("ğŸš€ VERÄ° SETLERÄ° BÄ°RLEÅTÄ°RÄ°LÄ°YOR...")

# Hata ayÄ±klama modunda CSV'leri oku
dfs = []

# 1. Ana veri seti - hata ayÄ±klama ile oku
print("ğŸ“‚ cumulative_2025.10.04_02.11.48.csv yÃ¼kleniyor...")
try:
    # Ã–nce hatanÄ±n olduÄŸu satÄ±rÄ± bulalÄ±m
    df1 = pd.read_csv('cumulative_2025.10.04_02.11.48.csv', on_bad_lines='skip')
    print(f"   âœ… {len(df1):,} kayÄ±t yÃ¼klendi")
    dfs.append(df1)
except Exception as e:
    print(f"   âŒ Hata: {e}")
    # Alternatif yÃ¶ntem
    try:
        df1 = pd.read_csv('cumulative_2025.10.04_02.11.48.csv', error_bad_lines=False)
        print(f"   âœ… {len(df1):,} kayÄ±t yÃ¼klendi (hatalÄ± satÄ±rlar atlandÄ±)")
        dfs.append(df1)
    except:
        print("   âŒ Alternatif yÃ¶ntem de baÅŸarÄ±sÄ±z")

# 2. K2 veri seti  
print("ğŸ“‚ k2pandc_2025.10.04_02.12.05.csv yÃ¼kleniyor...")
try:
    df2 = pd.read_csv('k2pandc_2025.10.04_02.12.05.csv', on_bad_lines='skip')
    print(f"   âœ… {len(df2):,} kayÄ±t yÃ¼klendi")
    dfs.append(df2)
except Exception as e:
    print(f"   âŒ Hata: {e}")

# 3. TOI veri seti
print("ğŸ“‚ TOI_2025.10.04_02.11.58.csv yÃ¼kleniyor...")
try:
    df3 = pd.read_csv('TOI_2025.10.04_02.11.58.csv', on_bad_lines='skip')
    print(f"   âœ… {len(df3):,} kayÄ±t yÃ¼klendi")
    dfs.append(df3)
except Exception as e:
    print(f"   âŒ Hata: {e}")

if not dfs:
    print("âŒ HiÃ§bir CSV yÃ¼klenemedi!")
    exit()

# Ortak sÃ¼tunlarÄ± bul
print("\nğŸ” ORTAK SÃœTUNLAR BULUNUYOR...")
common_columns = set(dfs[0].columns)
for df in dfs[1:]:
    common_columns = common_columns.intersection(set(df.columns))

print(f"   ğŸ¯ {len(common_columns)} ortak sÃ¼tun bulundu:")
for col in sorted(list(common_columns))[:15]:  # Ä°lk 15'i gÃ¶ster
    print(f"      â€¢ {col}")

# Sadece ortak sÃ¼tunlarÄ± seÃ§erek birleÅŸtir
combined_dfs = []
for i, df in enumerate(dfs):
    df_common = df[list(common_columns)].copy()
    combined_dfs.append(df_common)
    print(f"   ğŸ“Š DataFrame {i+1}: {len(df_common):,} kayÄ±t")

# TÃ¼mÃ¼nÃ¼ birleÅŸtir
print("\nğŸ”„ VERÄ° SETLERÄ° BÄ°RLEÅTÄ°RÄ°LÄ°YOR...")
final_df = pd.concat(combined_dfs, ignore_index=True)
print(f"   âœ… TOPLAM: {len(final_df):,} kayÄ±t")
print(f"   ğŸ“ˆ SÃœTUN: {final_df.shape[1]}")

# Gezegen sÃ¼tununu bul
print("\nğŸª GEZEGEN SÃœTUNU ARA...")
planet_columns = [col for col in final_df.columns 
                 if 'disposition' in col.lower() 
                 or 'koi' in col.lower() 
                 or 'tfopwg' in col.lower()
                 or 'planet' in col.lower()]

if planet_columns:
    for col in planet_columns:
        print(f"   ğŸ” {col}: {final_df[col].nunique()} farklÄ± deÄŸer")
        if final_df[col].nunique() < 10:  # Sadece sÄ±nÄ±flandÄ±rma sÃ¼tunlarÄ±nÄ± gÃ¶ster
            print(f"      ğŸ“Š {dict(final_df[col].value_counts())}")
else:
    print("   âŒ AÃ§Ä±k gezegen sÃ¼tunu bulunamadÄ±")

# Ä°lk birkaÃ§ kaydÄ± gÃ¶ster
print("\nğŸ‘€ Ä°LK 3 KAYIT:")
print(final_df.head(3))

# Kaydet
print("\nğŸ’¾ YENÄ° VERÄ° SETÄ° KAYDEDÄ°LÄ°YOR...")
final_df.to_csv('combined_exoplanet_data.csv', index=False)
print("   âœ… combined_exoplanet_data.csv kaydedildi")

print(f"\nğŸ‰ Ä°ÅLEM TAMAMLANDI!")
print(f"   ğŸ“ Yeni veri seti: {len(final_df):,} kayÄ±t")
print(f"   ğŸ¯ KullanÄ±labilir sÃ¼tun: {final_df.shape[1]}")